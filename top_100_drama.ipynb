{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 2,
>>>>>>> Mark
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "page = requests.get('https://www.imdb.com/list/ls076655138/')\n",
    "print(page)\n",
    "soup = BeautifulSoup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"\"\"\" and add list at their appropiate point to create our dataframe\n",
    "\"\"\"df = pd.DataFrame({\n",
    "    'Movie':,\n",
    "    'Description':,\n",
    "    'Release Date':,\n",
    "    'Director':director_name,\n",
    "    'Rating':,\n",
    "    'Duration':,\n",
    "    'Genre':genre,\n",
    "    'Stars':stars,\n",
    "    'Filming Dates':\n",
    "})\n",
    "\n",
    "df.to_csv('top_100_drama.csv')\"\"\""
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping site for data on genre, stars(actors) and filming dates\n",
    "\n",
    "genre_data = soup.find_all('span',class_='genre')\n",
    "cast_data = soup.find_all('p', class_=\"text-muted text-small\")\n",
    "\n",
    "directors_and_actors = []   # empty list to store text data from cast\n",
    "genre = []     # empty list to store text data from genre\n",
    "director_name = []      # empty list to store director's names in order\n",
    "stars = []         # empty list to store actor's names in order\n",
    "\n",
    "for i in range(len(genre_data)):\n",
    "    genre.append(genre_data[i].text.strip())\n",
    "\n",
    "for i in range(1,len(cast_data),3):\n",
    "    directors_and_actors.append(cast_data[i].text.strip())\n",
    "\n",
    "# Seperating the director's and actor's names from list\n",
    "for i in range(len(directors_and_actors)):\n",
    "    empty_string = ''\n",
    "    for j in range(len(directors_and_actors[i])):\n",
    "        if ord(directors_and_actors[i][j]) != 124:\n",
    "            empty_string = empty_string + directors_and_actors[i][j]\n",
    "        else:\n",
    "            director_name.append(empty_string.strip('Director:').strip())\n",
    "            break\n",
    "    empty_string = ''\n",
    "    for k in range(1,len(directors_and_actors[i])):\n",
    "        if ord(directors_and_actors[i][-k]) != 124:\n",
    "            empty_string = directors_and_actors[i][-k] + empty_string\n",
    "        else:\n",
    "            stars.append(empty_string.strip().strip('Stars:').replace('\\n',''))\n",
    "            break"
>>>>>>> Mark
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e171acd309c06983148c9856e741c79a7072f11ec9d548c93ae4f1382cc847af"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('strive': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
